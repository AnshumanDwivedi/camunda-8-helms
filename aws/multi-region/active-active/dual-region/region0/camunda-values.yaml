# Chart values for the Camunda Platform 8 Helm chart.
# This file deliberately contains only the values that differ from the defaults.
# For changes and documentation, use your favorite diff tool to compare it with:
# https://github.com/camunda/camunda-platform-helm/blob/main/charts/camunda-platform/values.yaml

global:
  # Multiregion options for Zeebe
  #
  ## WARNING: In order to get your multi-region setup covered by Camunda enterprise support you MUST get your configuration and run books reviewed by Camunda before going to production.
  # This is necessary for us to be able to help you in case of outages, due to the complexity of operating multi-region setups and the dependencies to the underlying Kubernetes prerequisites.
  # If you operate this in the wrong way you risk corruption and complete loss of all data especially in the dual-region case.
  # If you can, consider three regions. Please, contact your customer success manager as soon as you start planning a multi-region setup.
  # Camunda reserves the right to limit support if no review was done prior to launch or the review showed significant risks.
  multiregion:
    # number of regions that this Camunda Platform instance is stretched across
    regions: 2
    # unique id of the region. Should start at 0 for easy computation. With 2 regions, you would have region 0 and 1.
    regionId: 0
  image:
    tag: latest
  identity:
    auth:
      # Disable the Identity authentication
      # it will fall back to basic-auth: demo/demo as default user
      enabled: false

operate:
  env:
    - name: CAMUNDA_OPERATE_BACKUP_REPOSITORYNAME
      value: "camunda_backup"
tasklist:
  env:
    - name: CAMUNDA_TASKLIST_BACKUP_REPOSITORYNAME
      value: "camunda_backup"

identity:
  enabled: false

optimize:
  enabled: false

connectors:
  enabled: true
  inbound:
    mode: credentials
  resources:
    requests:
      cpu: "100m"
      memory: "512M"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  env:
    - name: CAMUNDA_OPERATE_CLIENT_USERNAME
      value: demo
    - name: CAMUNDA_OPERATE_CLIENT_PASSWORD
      value: demo

zeebe:
  clusterSize: 4
  partitionCount: 4
  replicationFactor: 4
  affinity:
    podAntiAffinity: null
  env:
    - name: ZEEBE_BROKER_DATA_SNAPSHOTPERIOD
      value: "5m"
    - name: ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK
      value: "0.85"
    - name: ZEEBE_BROKER_DATA_DISKUSAGEREPLICATIONWATERMARK
      value: "0.87"
    - name: ZEEBE_BROKER_CLUSTER_INITIALCONTACTPOINTS
      value: "camunda-zeebe-0.camunda-zeebe.us-west-2.svc.cluster.local:26502, camunda-zeebe-1.camunda-zeebe.us-west-2.svc.cluster.local:26502, camunda-zeebe-0.camunda-zeebe.us-east-2.svc.cluster.local:26502, camunda-zeebe-1.camunda-zeebe.us-east-2.svc.cluster.local:26502"
    - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH2_CLASSNAME
      value: "io.camunda.zeebe.exporter.ElasticsearchExporter"
    - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH2_ARGS_URL
      value: "http://camunda-elasticsearch.us-west-2.svc.cluster.local:9200"
    - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH2_ARGS_BULK_SIZE
      value: "1"
    - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH2_ARGS_INDEX_PREFIX
      value: "zeebe-record"
    - name: ZEEBE_BROKER_CLUSTER_MEMBERSHIP_PROBETIMEOUT
      value: "500ms"
  pvcSize: 100Gi

  resources:
    requests:
      cpu: "100m"
      memory: "512M"
    limits:
      cpu: "512m"
      memory: "2Gi"

zeebe-gateway:
  replicas: 1

  env:
    - name: ZEEBE_GATEWAY_CLUSTER_MEMBERSHIP_PROBETIMEOUT
      value: "500ms"
    - name: ZEEBE_GATEWAY_CLUSTER_INITIALCONTACTPOINTS
      value: "camunda-zeebe-0.camunda-zeebe.us-west-2.svc.cluster.local:26502, camunda-zeebe-1.camunda-zeebe.us-west-2.svc.cluster.local:26502, camunda-zeebe-0.camunda-zeebe.us-east-2.svc.cluster.local:26502, camunda-zeebe-1.camunda-zeebe.us-east-2.svc.cluster.local:26502"

  resources:
    requests:
      cpu: "100m"
      memory: "512M"
    limits:
      cpu: "1000m"
      memory: "1Gi"

  logLevel: ERROR

elasticsearch:
  enabled: true
  master:
    replicaCount: 1
    resources:
      requests:
        cpu: "100m"
        memory: "512M"
      limits:
        cpu: "1000m"
        memory: "2Gi"
  data:
    replicaCount: 0
  coordinating:
    replicaCount: 0
  ingest:
    replicaCount: 0
  # data:
  #   replicaCount: 1
  minimumMasterNodes: 1
  # Allow no backup for single node setups
  clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"
