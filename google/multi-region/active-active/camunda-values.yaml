# Chart values for the Camunda Platform 8 Helm chart.
# This file deliberately contains only the values that differ from the defaults.
# For changes and documentation, use your favorite diff tool to compare it with:
# https://github.com/camunda/camunda-platform-helm/blob/main/charts/camunda-platform/values.yaml

global:
  # Multiregion options for Zeebe
  #
  ## WARNING: In order to get your multi-region setup covered by Camunda enterprise support you MUST get your configuration and run books reviewed by Camunda before going to production.
  # This is necessary for us to be able to help you in case of outages, due to the complexity of operating multi-region setups and the dependencies to the underlying Kubernetes prerequisites.
  # If you operate this in the wrong way you risk corruption and complete loss of all data especially in the dual-region case.
  # If you can, consider three regions. Please, contact your customer success manager as soon as you start planning a multi-region setup.
  # Camunda reserves the right to limit support if no review was done prior to launch or the review showed significant risks.
  multiregion:
    # number of regions that this Camunda Platform instance is stretched across
    regions: 3
  identity:
    auth:
      # Disable the Identity authentication
      # it will fall back to basic-auth: demo/demo as default user
      enabled: false
  elasticsearch:
    disableExporter: true

operate:
  env:
    - name: CAMUNDA_OPERATE_BACKUP_REPOSITORYNAME
      value: "camunda_backup"
tasklist:
  env:
    - name: CAMUNDA_TASKLIST_BACKUP_REPOSITORYNAME
      value: "camunda_backup"
      
identity:
  enabled: false

optimize:
  enabled: false

connectors:
  enabled: true
  inbound:
    mode: credentials
  resources:
    requests:
      cpu: "100m"
      memory: "512M"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  env:
    - name: CAMUNDA_OPERATE_CLIENT_USERNAME
      value: demo
    - name: CAMUNDA_OPERATE_CLIENT_PASSWORD
      value: demo

zeebe:
  clusterSize: 6
  partitionCount: 6
  replicationFactor: 3
  env:
    - name: ZEEBE_BROKER_DATA_SNAPSHOTPERIOD
      value: "5m"
    - name: ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK
      value: "0.85"
    - name: ZEEBE_BROKER_DATA_DISKUSAGEREPLICATIONWATERMARK
      value: "0.87"
    - name: ZEEBE_BROKER_CLUSTER_INITIALCONTACTPOINTS
      value: "camunda-zeebe-0.camunda-zeebe.us-east1.svc.cluster.local:26502,camunda-zeebe-1.camunda-zeebe.us-east1.svc.cluster.local:26502,camunda-zeebe-2.camunda-zeebe.us-east1.svc.cluster.local:26502,camunda-zeebe-3.camunda-zeebe.us-east1.svc.cluster.local:26502,camunda-zeebe-0.camunda-zeebe.europe-west1.svc.cluster.local:26502,camunda-zeebe-1.camunda-zeebe.europe-west1.svc.cluster.local:26502,camunda-zeebe-2.camunda-zeebe.europe-west1.svc.cluster.local:26502,camunda-zeebe-3.camunda-zeebe.europe-west1.svc.cluster.local:26502"
    - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCHREGION0_CLASSNAME
      value: "io.camunda.zeebe.exporter.ElasticsearchExporter"
    - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCHREGION0_ARGS_URL
      value: "http://elasticsearch-master-hl.us-east1.svc.cluster.local:9200"
    - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCHREGION1_CLASSNAME
      value: "io.camunda.zeebe.exporter.ElasticsearchExporter"
    - name: ZEEBE_BROKER_EXPORTERS_ELASTICSEARCHREGION1_ARGS_URL
      value: "http://elasticsearch-master-hl.europe-west1.svc.cluster.local:9200"
    # Enable JSON logging for Google Cloud Stackdriver
    - name: ZEEBE_LOG_APPENDER
      value: Stackdriver
    - name: ZEEBE_LOG_STACKDRIVER_SERVICENAME
      value: zeebe
    - name: ZEEBE_LOG_STACKDRIVER_SERVICEVERSION
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
  pvcSize: 1Gi

  resources:
    requests:
      cpu: "100m"
      memory: "512M"
    limits:
      cpu: "512m"
      memory: "2Gi"

zeebe-gateway:
  replicas: 1

  resources:
    requests:
      cpu: "100m"
      memory: "512M"
    limits:
      cpu: "1000m"
      memory: "1Gi"

  logLevel: ERROR

elasticsearch:
  enabled: true
  #  imageTag: 7.17.3
  master:
    replicaCount: 2
    resources:
      requests:
        cpu: "100m"
        memory: "512M"
      limits:
        cpu: "1000m"
        memory: "2Gi"
    persistence:
      size: 15Gi
  
  initContainers:
    - name: install-gcs-plugin
      image: elasticsearch:7.17.10
      securityContext:
        privileged: true
      command:
        - sh
      args:
        - -c
        - |
          ./bin/elasticsearch-plugin install --batch repository-gcs
          ./bin/elasticsearch-keystore add-file -f gcs.client.default.credentials_file ./key/gcs_backup_key.json
          cp -a ./config/elasticsearch.keystore /tmp/keystore
      volumeMounts:
        - name: plugins
          mountPath: /usr/share/elasticsearch/plugins
        - name: gcs-backup-key
          mountPath: /usr/share/elasticsearch/key
        - name: keystore
          mountPath: /tmp/keystore
  extraVolumes:
    - name: plugins
      emptyDir: {}
    - name: keystore
      emptyDir: {}
    - name: gcs-backup-key
      secret:
        secretName: gcs-backup-key
  extraVolumeMounts:
    - name: plugins
      mountPath: /usr/share/elasticsearch/plugins
      readOnly: false
    - mountPath: /usr/share/elasticsearch/key
      name: gcs-backup-key
    - name: keystore
      mountPath: /usr/share/elasticsearch/config/elasticsearch.keystore
      subPath: elasticsearch.keystore
  # Allow no backup for single node setups ??? Not included in es values.yaml
  # clusterHealthCheckParams: "wait_for_status=yellow&timeout=1s"




  # # Request smaller persistent volumes.
  # volumeClaimTemplate:
  #   accessModes: [ "ReadWriteOnce" ]
  #   storageClassName: "standard"
  #   resources:
  #     requests:
  #       storage: 15Gi
